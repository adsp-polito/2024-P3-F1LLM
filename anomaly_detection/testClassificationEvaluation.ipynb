{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for evaluation\n",
    "class SingleDriverDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Dataset to wrap the data for a single driver.\n",
    "        \n",
    "        Args:\n",
    "            data (numpy.ndarray): The feature data (e.g., last 3 laps of a driver).\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "# Model Definition\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-LSTM hybrid model for classification.\n",
    "    Combines convolutional layers for feature extraction and LSTM layers for sequential modeling.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=n_features, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN layers\n",
    "        x = x.permute(0, 2, 1)  # Switch to (batch_size, n_features, sequence_length)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # LSTM layers\n",
    "        x = x.permute(0, 2, 1)  # Switch back to (batch_size, sequence_length, features)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = x[:, -1, :]  # Use the last LSTM output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def predict_anomaly(model_path, driver_data, sequence_length, n_classes=8, anomaly_classes=None):\n",
    "    \"\"\"\n",
    "    Predicts the anomaly for a single driver's data using a sliding window approach.\n",
    "    Returns a single prediction using maximum average probability and the aggregated probabilities for all classes.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the saved model (.pth file).\n",
    "        driver_data (numpy.ndarray): The preprocessed and normalized data of the driver.\n",
    "        sequence_length (int): Length of the sliding window.\n",
    "        n_classes (int): Number of output classes.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[str, dict]: Predicted anomaly class (maximum average probability) and aggregated probabilities for all classes.\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNNLSTMModel(n_features=driver_data.shape[1], n_classes=n_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Generate sliding windows dynamically\n",
    "    sliding_windows = []\n",
    "    for i in range(len(driver_data) - sequence_length + 1):\n",
    "        window = driver_data[i:i + sequence_length]\n",
    "        sliding_windows.append(window)\n",
    "    \n",
    "    sliding_windows = np.array(sliding_windows)  # Convert to NumPy array\n",
    "\n",
    "    # Wrap sliding windows in a Dataset and DataLoader\n",
    "    dataset = SingleDriverDataset(sliding_windows)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Make predictions for each window\n",
    "    probabilities = torch.zeros((len(sliding_windows), n_classes), device=device)  # Store probabilities for all windows\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, inputs in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities[idx] = F.softmax(outputs, dim=1).squeeze()  # Store probabilities\n",
    "\n",
    "    # Aggregated Probabilities\n",
    "    mean_probabilities = probabilities.mean(dim=0).cpu().numpy()  # Average probabilities across all windows\n",
    "    aggregated_probabilities = {\n",
    "        anomaly_classes[i]: float(mean_probabilities[i]) for i in range(n_classes)\n",
    "    }\n",
    "\n",
    "    # Majority Voting based on probabilities\n",
    "    most_probable_class_idx = mean_probabilities.argmax()  # Get the class with the highest average probability\n",
    "    predicted_class = anomaly_classes[most_probable_class_idx]\n",
    "\n",
    "    return predicted_class, aggregated_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Anomaly: Braking System\n",
      "Predicted Anomaly: Suspension and Drive\n",
      "\n",
      "Aggregated Probabilities:\n",
      "Suspension and Drive: 42.74%\n",
      "Braking System: 23.92%\n",
      "Engine: 22.36%\n",
      "Cooling System: 10.95%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the saved model\n",
    "model_path = \"../classification_models/classification_model_epoch20_loss0.0789.pth\"\n",
    "folder_path = \"../Dataset/OnlyFailuresByDriver/npz_failures_MinMaxScaler_normalized_test_firstDriver.npz\"\n",
    "\n",
    "# Load the data for the first driver\n",
    "failureFirstDriver = np.load(folder_path)[\"data\"]\n",
    "df = pd.DataFrame(failureFirstDriver)\n",
    "\n",
    "# Convert DataFrame to NumPy array for processing\n",
    "driver_data = df.to_numpy()\n",
    "\n",
    "# Extract the actual failure class (last column)\n",
    "actual_failure = driver_data[:, -1]  # Last column contains the true failure class indices\n",
    "\n",
    "# Remove the last column to get the input features\n",
    "driver_data = driver_data[:, :-1]\n",
    "\n",
    "# Define the anomaly classes\n",
    "anomaly_classes = [\"Others\", \"Braking System\", \"Engine\", \"Power Unit\", \"Cooling System\", \n",
    "                   \"Suspension and Drive\", \"Aerodynamics and Tyres\", \"Transmission and Gearbox\"]\n",
    "n_classes = len(anomaly_classes)   # Number of distinct failure classes\n",
    "\n",
    "# Sliding window length (sequence length for LSTM)\n",
    "sequence_length = 20  # Use the entire data as a single sequence\n",
    "\n",
    "# Predict the anomaly using sliding window with aggregation\n",
    "predicted_anomaly, aggregated_probabilities = predict_anomaly(\n",
    "    model_path=model_path,\n",
    "    driver_data=driver_data,\n",
    "    sequence_length=sequence_length,\n",
    "    n_classes=n_classes,\n",
    "    anomaly_classes=anomaly_classes\n",
    ")\n",
    "\n",
    "# Map the actual failure index to its corresponding class name\n",
    "actual_failure_class = anomaly_classes[int(actual_failure[0])]\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Anomaly: {actual_failure_class}\")\n",
    "print(f\"Predicted Anomaly: {predicted_anomaly}\")\n",
    "print(\"\\nAggregated Probabilities:\")\n",
    "\n",
    "# Sort aggregated probabilities by value in descending order\n",
    "sorted_probabilities = sorted(aggregated_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print only probabilities > 1e-3 (0.001)\n",
    "for anomaly, probability in sorted_probabilities:\n",
    "    if probability > 1e-3:\n",
    "        print(f\"{anomaly}: {probability:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
