{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fastf1\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick all the anomalies from 2014-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for Abu Dhabi Grand Prix (2019-12-01 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "year = range(2014, 2020)\n",
    "for y in year:\n",
    "    try:\n",
    "        schedule = fastf1.get_event_schedule(y)\n",
    "        for race in schedule.iterrows():\n",
    "            race_info = race[1]\n",
    "            event_name = race_info['EventName']  # Nome specifico della gara\n",
    "            print(f\"Loading data for {event_name} ({race_info['EventDate']})\")\n",
    "\n",
    "            try:\n",
    "                race_session = fastf1.get_session(y, event_name, 'R')\n",
    "                race_session.load(telemetry=False, laps=False, weather=False) #IMPORTANT\n",
    "                clear_output()\n",
    "                print(f\"Loaded data for {event_name} ({race_info['EventDate']})\")\n",
    "\n",
    "                # Filtra per status rilevanti\n",
    "                relevant_status = race_session.results[(race_session.results['Status'] != 'Finished') & \n",
    "                                                       (~race_session.results['Status'].str.contains('lap', case=False, na=False))&\n",
    "                                                       (race_session.results['Status'] != 'Collision')&\n",
    "                                                       (race_session.results['Status'] != 'Disqualified')&\n",
    "                                                       (race_session.results['Status'] != 'Collision damage')&\n",
    "                                                       (race_session.results['Status'] != 'Wheel nut')&\n",
    "                                                       (race_session.results['Status'] != 'Accident')&\n",
    "                                                       (race_session.results['Status'] != 'Retired')&\n",
    "                                                       (race_session.results['Status'] != 'Withdrew')&\n",
    "                                                       (race_session.results['Status'] != 'Spun off')&\n",
    "                                                       (race_session.results['Status'] != 'Seat')&\n",
    "                                                       (race_session.results['Status'] != 'Debris')&\n",
    "                                                       (race_session.results['Status'] != 'Excluded')&\n",
    "                                                       (race_session.results['Status'] != '')&\n",
    "                                                       (race_session.results['Status'] != 'Illness')]\n",
    "                \n",
    "                # Crea il DataFrame con solo dati rilevanti per le anomalies\n",
    "                partial_csv = relevant_status[['DriverNumber', 'Status']].reset_index(drop=True)\n",
    "                event_name = race_session.event['EventName']\n",
    "                event_date = race_session.event['EventDate']\n",
    "                partial_csv = partial_csv.assign(EventName=event_name, EventDate=event_date)\n",
    "                \n",
    "                all_data.append(partial_csv)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load data for {event_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process year {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat(all_data, ignore_index=True)\n",
    "final_data = final_data.drop_duplicates()\n",
    "# final_data['EventDate'] = final_data['EventDate'].astype(str)\n",
    "# final_data[final_data['EventDate'].str.startswith(\"2017\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['EventDate'] = final_data['EventDate'].astype(str)\n",
    "final_data[final_data['EventDate'].str.startswith(\"2019\")].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick all the anomalies from 2020-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for Abu Dhabi Grand Prix (2024-12-08 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_data = []\n",
    "\n",
    "year = range(2020, 2025)\n",
    "for y in year:\n",
    "    try:\n",
    "        schedule = fastf1.get_event_schedule(y)\n",
    "        for race in schedule.iterrows():\n",
    "            race_info = race[1]\n",
    "            event_name = race_info['EventName']  # Nome specifico della gara\n",
    "            print(f\"Loading data for {event_name} ({race_info['EventDate']})\")\n",
    "\n",
    "            try:\n",
    "                race_session = fastf1.get_session(y, event_name, 'R')\n",
    "                race_session.load(telemetry=False, laps=False, weather=False) #IMPORTANT\n",
    "                clear_output()\n",
    "                print(f\"Loaded data for {event_name} ({race_info['EventDate']})\")\n",
    "\n",
    "                # Filtra per status rilevanti\n",
    "                relevant_status = race_session.results[(race_session.results['Status'] != 'Finished') & \n",
    "                                                       (~race_session.results['Status'].str.contains('lap', case=False, na=False))&\n",
    "                                                       (race_session.results['Status'] != 'Collision')&\n",
    "                                                       (race_session.results['Status'] != 'Disqualified')&\n",
    "                                                       (race_session.results['Status'] != 'Collision damage')&\n",
    "                                                       (race_session.results['Status'] != 'Wheel nut')&\n",
    "                                                       (race_session.results['Status'] != 'Accident')&\n",
    "                                                       (race_session.results['Status'] != 'Retired')&\n",
    "                                                       (race_session.results['Status'] != 'Withdrew')&\n",
    "                                                       (race_session.results['Status'] != 'Spun off')&\n",
    "                                                       (race_session.results['Status'] != 'Seat')&\n",
    "                                                       (race_session.results['Status'] != 'Debris')&\n",
    "                                                       (race_session.results['Status'] != 'Excluded')&\n",
    "                                                       (race_session.results['Status'] != '')&\n",
    "                                                       (race_session.results['Status'] != 'Illness')]\n",
    "                \n",
    "                # Crea il DataFrame con solo dati rilevanti per le anomalies\n",
    "                partial_csv = relevant_status[['DriverNumber', 'Status']].reset_index(drop=True)\n",
    "                event_name = race_session.event['EventName']\n",
    "                event_date = race_session.event['EventDate']\n",
    "                partial_csv = partial_csv.assign(EventName=event_name, EventDate=event_date)\n",
    "                \n",
    "                all_data.append(partial_csv)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load data for {event_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process year {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the two dataframes\n",
    "all_data = pd.concat(all_data, ignore_index=True)\n",
    "all_data = all_data.drop_duplicates()\n",
    "final_data = pd.concat([final_data,all_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['EventDate'] = final_data['EventDate'].astype(str)\n",
    "final_data[final_data['EventDate'].str.startswith(\"2024\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written successfully to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path and save it\n",
    "csv_file = 'Failures2014_2024.csv'\n",
    "final_data.to_csv(csv_file, mode='w', header=True, index=False)\n",
    "\n",
    "print(\"Data has been written successfully to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DriverNumber</th>\n",
       "      <th>Status</th>\n",
       "      <th>EventName</th>\n",
       "      <th>EventDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>ERS</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014-03-16 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>ERS</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014-03-16 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Oil pressure</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014-03-16 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Engine</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014-03-16 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Engine</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014-03-16 06:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DriverNumber        Status              EventName            EventDate\n",
       "0             8           ERS  Australian Grand Prix  2014-03-16 06:00:00\n",
       "1            13           ERS  Australian Grand Prix  2014-03-16 06:00:00\n",
       "2             9  Oil pressure  Australian Grand Prix  2014-03-16 06:00:00\n",
       "3             1        Engine  Australian Grand Prix  2014-03-16 06:00:00\n",
       "4            44        Engine  Australian Grand Prix  2014-03-16 06:00:00"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anomalies = pd.read_csv('Failures2014_2024.csv')\n",
    "df_anomalies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the year from the 'EventDate' column\n",
    "def extract_year(date):\n",
    "    if '/' in date:  # Checks if the format contains '/'\n",
    "        return '20'+ date.split('/')[2].split(' ')[0]  # Extracts the last part (year)\n",
    "    elif '-' in date:  # Checks if the format contains '.'\n",
    "        return date.split('-')[0]  # Extracts the first part (year)\n",
    "    else:\n",
    "        return None  # Returns None if the format is not recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DriverNumber</th>\n",
       "      <th>Status</th>\n",
       "      <th>EventName</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>ERS</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>ERS</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Oil pressure</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Engine</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Engine</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>10</td>\n",
       "      <td>Hydraulics</td>\n",
       "      <td>Hungarian Grand Prix</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>22</td>\n",
       "      <td>Overheating</td>\n",
       "      <td>Italian Grand Prix</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>14</td>\n",
       "      <td>Brakes</td>\n",
       "      <td>Mexico City Grand Prix</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>23</td>\n",
       "      <td>Radiator</td>\n",
       "      <td>Las Vegas Grand Prix</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>10</td>\n",
       "      <td>Engine</td>\n",
       "      <td>Las Vegas Grand Prix</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DriverNumber        Status               EventName  Year\n",
       "0               8           ERS   Australian Grand Prix  2014\n",
       "1              13           ERS   Australian Grand Prix  2014\n",
       "2               9  Oil pressure   Australian Grand Prix  2014\n",
       "3               1        Engine   Australian Grand Prix  2014\n",
       "4              44        Engine   Australian Grand Prix  2014\n",
       "..            ...           ...                     ...   ...\n",
       "405            10    Hydraulics    Hungarian Grand Prix  2024\n",
       "406            22   Overheating      Italian Grand Prix  2024\n",
       "407            14        Brakes  Mexico City Grand Prix  2024\n",
       "408            23      Radiator    Las Vegas Grand Prix  2024\n",
       "409            10        Engine    Las Vegas Grand Prix  2024\n",
       "\n",
       "[410 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anomalies['Year'] = df_anomalies['EventDate'].apply(extract_year)\n",
    "df_anomalies.drop('EventDate', axis=1, inplace=True)\n",
    "df_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Status\n",
       " Engine            79\n",
       " Brakes            49\n",
       " Gearbox           42\n",
       " Power Unit        42\n",
       " Suspension        25\n",
       " Hydraulics        15\n",
       " Electrical        14\n",
       " Power loss        13\n",
       " Wheel             11\n",
       " Oil leak          10\n",
       " Overheating        8\n",
       " Water pressure     7\n",
       " Puncture           7\n",
       " Mechanical         7\n",
       " Turbo              6\n",
       " Battery            5\n",
       " ERS                5\n",
       " Exhaust            5\n",
       " Fuel pressure      5\n",
       " Water leak         4\n",
       " Electronics        4\n",
       " Tyre               4\n",
       " Undertray          4\n",
       " Radiator           3\n",
       " Transmission       3\n",
       " Rear wing          3\n",
       " Front wing         3\n",
       " Throttle           2\n",
       " Technical          2\n",
       " Fuel leak          2\n",
       " Clutch             2\n",
       " Damage             2\n",
       " Steering           2\n",
       " Driveshaft         2\n",
       " Vibrations         2\n",
       " Oil pressure       2\n",
       " Spark plugs        1\n",
       " Brake duct         1\n",
       " Out of fuel        1\n",
       " Drivetrain         1\n",
       " Fuel pump          1\n",
       " Cooling system     1\n",
       " Water pump         1\n",
       " Fuel system        1\n",
       " Differential       1\n",
       " Name: count, dtype: int64,\n",
       " (410, 4))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_counts = df_anomalies['Status'].value_counts()\n",
    "failure_counts, df_anomalies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies.to_csv('Failures2014_2024_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pairs_count = df_anomalies[['EventName', 'Year']].drop_duplicates().shape[0]\n",
    "unique_pairs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(year, event_name,driver):\n",
    "    try:\n",
    "        race_session = fastf1.get_session(year, event_name, 'R')\n",
    "        race_session.load(telemetry=True, laps=True, weather=False)\n",
    "        clear_output()\n",
    "        print(f\"Loaded data for {event_name} ({race_session.event['EventDate']})\")\n",
    "        return race_session.laps.pick_driver(str(driver))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data for {event_name}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for Singapore (2019-09-22 00:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benot\\AppData\\Roaming\\Python\\Python311\\site-packages\\fastf1\\core.py:3022: FutureWarning: pick_driver is deprecated and will be removed in a future release. Use pick_drivers instead.\n",
      "  warnings.warn((\"pick_driver is deprecated and will be removed\"\n"
     ]
    }
   ],
   "source": [
    "test = retrieve_data(2019, 'Singapore', 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>LapStartTime</th>\n",
       "      <th>LapStartDate</th>\n",
       "      <th>LapTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0 days 00:35:42.865000</td>\n",
       "      <td>0 days 00:33:40.429000</td>\n",
       "      <td>2019-09-22 12:13:41.397</td>\n",
       "      <td>0 days 00:02:02.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0 days 00:37:35.913000</td>\n",
       "      <td>0 days 00:35:42.865000</td>\n",
       "      <td>2019-09-22 12:15:43.833</td>\n",
       "      <td>0 days 00:01:53.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0 days 00:39:27.974000</td>\n",
       "      <td>0 days 00:37:35.913000</td>\n",
       "      <td>2019-09-22 12:17:36.881</td>\n",
       "      <td>0 days 00:01:52.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0 days 00:41:17.683000</td>\n",
       "      <td>0 days 00:39:27.974000</td>\n",
       "      <td>2019-09-22 12:19:28.942</td>\n",
       "      <td>0 days 00:01:49.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0 days 00:43:07.634000</td>\n",
       "      <td>0 days 00:41:17.683000</td>\n",
       "      <td>2019-09-22 12:21:18.651</td>\n",
       "      <td>0 days 00:01:49.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0 days 00:44:57.276000</td>\n",
       "      <td>0 days 00:43:07.634000</td>\n",
       "      <td>2019-09-22 12:23:08.602</td>\n",
       "      <td>0 days 00:01:49.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0 days 00:46:47.017000</td>\n",
       "      <td>0 days 00:44:57.276000</td>\n",
       "      <td>2019-09-22 12:24:58.244</td>\n",
       "      <td>0 days 00:01:49.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0 days 00:48:35.479000</td>\n",
       "      <td>0 days 00:46:47.017000</td>\n",
       "      <td>2019-09-22 12:26:47.985</td>\n",
       "      <td>0 days 00:01:48.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0 days 00:50:24.743000</td>\n",
       "      <td>0 days 00:48:35.479000</td>\n",
       "      <td>2019-09-22 12:28:36.447</td>\n",
       "      <td>0 days 00:01:49.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0 days 00:52:16.735000</td>\n",
       "      <td>0 days 00:50:24.743000</td>\n",
       "      <td>2019-09-22 12:30:25.711</td>\n",
       "      <td>0 days 00:01:51.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0 days 00:54:07.835000</td>\n",
       "      <td>0 days 00:52:16.735000</td>\n",
       "      <td>2019-09-22 12:32:17.703</td>\n",
       "      <td>0 days 00:01:51.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0 days 00:55:58</td>\n",
       "      <td>0 days 00:54:07.835000</td>\n",
       "      <td>2019-09-22 12:34:08.803</td>\n",
       "      <td>0 days 00:01:50.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0 days 00:57:53.228000</td>\n",
       "      <td>0 days 00:55:58</td>\n",
       "      <td>2019-09-22 12:35:58.968</td>\n",
       "      <td>0 days 00:01:55.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0 days 00:59:59.704000</td>\n",
       "      <td>0 days 00:57:53.228000</td>\n",
       "      <td>2019-09-22 12:37:54.196</td>\n",
       "      <td>0 days 00:02:06.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0 days 01:01:46.387000</td>\n",
       "      <td>0 days 00:59:59.704000</td>\n",
       "      <td>2019-09-22 12:40:00.672</td>\n",
       "      <td>0 days 00:01:46.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0 days 01:03:37.905000</td>\n",
       "      <td>0 days 01:01:46.387000</td>\n",
       "      <td>2019-09-22 12:41:47.355</td>\n",
       "      <td>0 days 00:01:51.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0 days 01:05:30.046000</td>\n",
       "      <td>0 days 01:03:37.905000</td>\n",
       "      <td>2019-09-22 12:43:38.873</td>\n",
       "      <td>0 days 00:01:52.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0 days 01:07:18.264000</td>\n",
       "      <td>0 days 01:05:30.046000</td>\n",
       "      <td>2019-09-22 12:45:31.014</td>\n",
       "      <td>0 days 00:01:48.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0 days 01:09:05.578000</td>\n",
       "      <td>0 days 01:07:18.264000</td>\n",
       "      <td>2019-09-22 12:47:19.232</td>\n",
       "      <td>0 days 00:01:47.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0 days 01:10:52.424000</td>\n",
       "      <td>0 days 01:09:05.578000</td>\n",
       "      <td>2019-09-22 12:49:06.546</td>\n",
       "      <td>0 days 00:01:46.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0 days 01:12:40.525000</td>\n",
       "      <td>0 days 01:10:52.424000</td>\n",
       "      <td>2019-09-22 12:50:53.392</td>\n",
       "      <td>0 days 00:01:48.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0 days 01:14:28.831000</td>\n",
       "      <td>0 days 01:12:40.525000</td>\n",
       "      <td>2019-09-22 12:52:41.493</td>\n",
       "      <td>0 days 00:01:48.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0 days 01:16:19.816000</td>\n",
       "      <td>0 days 01:14:28.831000</td>\n",
       "      <td>2019-09-22 12:54:29.799</td>\n",
       "      <td>0 days 00:01:50.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0 days 01:18:07.465000</td>\n",
       "      <td>0 days 01:16:19.816000</td>\n",
       "      <td>2019-09-22 12:56:20.784</td>\n",
       "      <td>0 days 00:01:47.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0 days 01:19:54.880000</td>\n",
       "      <td>0 days 01:18:07.465000</td>\n",
       "      <td>2019-09-22 12:58:08.433</td>\n",
       "      <td>0 days 00:01:47.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0 days 01:21:42.478000</td>\n",
       "      <td>0 days 01:19:54.880000</td>\n",
       "      <td>2019-09-22 12:59:55.848</td>\n",
       "      <td>0 days 00:01:47.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0 days 01:23:30.027000</td>\n",
       "      <td>0 days 01:21:42.478000</td>\n",
       "      <td>2019-09-22 13:01:43.446</td>\n",
       "      <td>0 days 00:01:47.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0 days 01:25:17.549000</td>\n",
       "      <td>0 days 01:23:30.027000</td>\n",
       "      <td>2019-09-22 13:03:30.995</td>\n",
       "      <td>0 days 00:01:47.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0 days 01:27:05.376000</td>\n",
       "      <td>0 days 01:25:17.549000</td>\n",
       "      <td>2019-09-22 13:05:18.517</td>\n",
       "      <td>0 days 00:01:47.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0 days 01:28:52.809000</td>\n",
       "      <td>0 days 01:27:05.376000</td>\n",
       "      <td>2019-09-22 13:07:06.344</td>\n",
       "      <td>0 days 00:01:47.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0 days 01:30:40.685000</td>\n",
       "      <td>0 days 01:28:52.809000</td>\n",
       "      <td>2019-09-22 13:08:53.777</td>\n",
       "      <td>0 days 00:01:47.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0 days 01:32:28.390000</td>\n",
       "      <td>0 days 01:30:40.685000</td>\n",
       "      <td>2019-09-22 13:10:41.653</td>\n",
       "      <td>0 days 00:01:47.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0 days 01:34:16.109000</td>\n",
       "      <td>0 days 01:32:28.390000</td>\n",
       "      <td>2019-09-22 13:12:29.358</td>\n",
       "      <td>0 days 00:01:47.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0 days 01:36:05.159000</td>\n",
       "      <td>0 days 01:34:16.109000</td>\n",
       "      <td>2019-09-22 13:14:17.077</td>\n",
       "      <td>0 days 00:01:49.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0 days 01:37:53.837000</td>\n",
       "      <td>0 days 01:36:05.159000</td>\n",
       "      <td>2019-09-22 13:16:06.127</td>\n",
       "      <td>0 days 00:01:48.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0 days 01:40:05.211000</td>\n",
       "      <td>0 days 01:37:53.837000</td>\n",
       "      <td>2019-09-22 13:17:54.805</td>\n",
       "      <td>0 days 00:02:11.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0 days 01:42:38.412000</td>\n",
       "      <td>0 days 01:40:05.211000</td>\n",
       "      <td>2019-09-22 13:20:06.179</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0 days 01:45:03.005000</td>\n",
       "      <td>0 days 01:42:38.412000</td>\n",
       "      <td>2019-09-22 13:22:39.380</td>\n",
       "      <td>0 days 00:02:24.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0 days 01:47:50.465000</td>\n",
       "      <td>0 days 01:45:03.005000</td>\n",
       "      <td>2019-09-22 13:25:03.973</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0 days 01:50:32.259000</td>\n",
       "      <td>0 days 01:47:50.465000</td>\n",
       "      <td>2019-09-22 13:27:51.433</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0 days 01:52:23.605000</td>\n",
       "      <td>0 days 01:50:32.259000</td>\n",
       "      <td>2019-09-22 13:30:33.227</td>\n",
       "      <td>0 days 00:01:51.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0 days 01:54:12.724000</td>\n",
       "      <td>0 days 01:52:23.605000</td>\n",
       "      <td>2019-09-22 13:32:24.573</td>\n",
       "      <td>0 days 00:01:49.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0 days 01:55:33.667000</td>\n",
       "      <td>0 days 01:54:12.724000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time           LapStartTime            LapStartDate  \\\n",
       "61  0 days 00:35:42.865000 0 days 00:33:40.429000 2019-09-22 12:13:41.397   \n",
       "62  0 days 00:37:35.913000 0 days 00:35:42.865000 2019-09-22 12:15:43.833   \n",
       "63  0 days 00:39:27.974000 0 days 00:37:35.913000 2019-09-22 12:17:36.881   \n",
       "64  0 days 00:41:17.683000 0 days 00:39:27.974000 2019-09-22 12:19:28.942   \n",
       "65  0 days 00:43:07.634000 0 days 00:41:17.683000 2019-09-22 12:21:18.651   \n",
       "66  0 days 00:44:57.276000 0 days 00:43:07.634000 2019-09-22 12:23:08.602   \n",
       "67  0 days 00:46:47.017000 0 days 00:44:57.276000 2019-09-22 12:24:58.244   \n",
       "68  0 days 00:48:35.479000 0 days 00:46:47.017000 2019-09-22 12:26:47.985   \n",
       "69  0 days 00:50:24.743000 0 days 00:48:35.479000 2019-09-22 12:28:36.447   \n",
       "70  0 days 00:52:16.735000 0 days 00:50:24.743000 2019-09-22 12:30:25.711   \n",
       "71  0 days 00:54:07.835000 0 days 00:52:16.735000 2019-09-22 12:32:17.703   \n",
       "72         0 days 00:55:58 0 days 00:54:07.835000 2019-09-22 12:34:08.803   \n",
       "73  0 days 00:57:53.228000        0 days 00:55:58 2019-09-22 12:35:58.968   \n",
       "74  0 days 00:59:59.704000 0 days 00:57:53.228000 2019-09-22 12:37:54.196   \n",
       "75  0 days 01:01:46.387000 0 days 00:59:59.704000 2019-09-22 12:40:00.672   \n",
       "76  0 days 01:03:37.905000 0 days 01:01:46.387000 2019-09-22 12:41:47.355   \n",
       "77  0 days 01:05:30.046000 0 days 01:03:37.905000 2019-09-22 12:43:38.873   \n",
       "78  0 days 01:07:18.264000 0 days 01:05:30.046000 2019-09-22 12:45:31.014   \n",
       "79  0 days 01:09:05.578000 0 days 01:07:18.264000 2019-09-22 12:47:19.232   \n",
       "80  0 days 01:10:52.424000 0 days 01:09:05.578000 2019-09-22 12:49:06.546   \n",
       "81  0 days 01:12:40.525000 0 days 01:10:52.424000 2019-09-22 12:50:53.392   \n",
       "82  0 days 01:14:28.831000 0 days 01:12:40.525000 2019-09-22 12:52:41.493   \n",
       "83  0 days 01:16:19.816000 0 days 01:14:28.831000 2019-09-22 12:54:29.799   \n",
       "84  0 days 01:18:07.465000 0 days 01:16:19.816000 2019-09-22 12:56:20.784   \n",
       "85  0 days 01:19:54.880000 0 days 01:18:07.465000 2019-09-22 12:58:08.433   \n",
       "86  0 days 01:21:42.478000 0 days 01:19:54.880000 2019-09-22 12:59:55.848   \n",
       "87  0 days 01:23:30.027000 0 days 01:21:42.478000 2019-09-22 13:01:43.446   \n",
       "88  0 days 01:25:17.549000 0 days 01:23:30.027000 2019-09-22 13:03:30.995   \n",
       "89  0 days 01:27:05.376000 0 days 01:25:17.549000 2019-09-22 13:05:18.517   \n",
       "90  0 days 01:28:52.809000 0 days 01:27:05.376000 2019-09-22 13:07:06.344   \n",
       "91  0 days 01:30:40.685000 0 days 01:28:52.809000 2019-09-22 13:08:53.777   \n",
       "92  0 days 01:32:28.390000 0 days 01:30:40.685000 2019-09-22 13:10:41.653   \n",
       "93  0 days 01:34:16.109000 0 days 01:32:28.390000 2019-09-22 13:12:29.358   \n",
       "94  0 days 01:36:05.159000 0 days 01:34:16.109000 2019-09-22 13:14:17.077   \n",
       "95  0 days 01:37:53.837000 0 days 01:36:05.159000 2019-09-22 13:16:06.127   \n",
       "96  0 days 01:40:05.211000 0 days 01:37:53.837000 2019-09-22 13:17:54.805   \n",
       "97  0 days 01:42:38.412000 0 days 01:40:05.211000 2019-09-22 13:20:06.179   \n",
       "98  0 days 01:45:03.005000 0 days 01:42:38.412000 2019-09-22 13:22:39.380   \n",
       "99  0 days 01:47:50.465000 0 days 01:45:03.005000 2019-09-22 13:25:03.973   \n",
       "100 0 days 01:50:32.259000 0 days 01:47:50.465000 2019-09-22 13:27:51.433   \n",
       "101 0 days 01:52:23.605000 0 days 01:50:32.259000 2019-09-22 13:30:33.227   \n",
       "102 0 days 01:54:12.724000 0 days 01:52:23.605000 2019-09-22 13:32:24.573   \n",
       "103 0 days 01:55:33.667000 0 days 01:54:12.724000                     NaT   \n",
       "\n",
       "                   LapTime  \n",
       "61  0 days 00:02:02.205000  \n",
       "62  0 days 00:01:53.048000  \n",
       "63  0 days 00:01:52.061000  \n",
       "64  0 days 00:01:49.709000  \n",
       "65  0 days 00:01:49.951000  \n",
       "66  0 days 00:01:49.642000  \n",
       "67  0 days 00:01:49.741000  \n",
       "68  0 days 00:01:48.462000  \n",
       "69  0 days 00:01:49.264000  \n",
       "70  0 days 00:01:51.992000  \n",
       "71  0 days 00:01:51.100000  \n",
       "72  0 days 00:01:50.165000  \n",
       "73  0 days 00:01:55.228000  \n",
       "74  0 days 00:02:06.476000  \n",
       "75  0 days 00:01:46.683000  \n",
       "76  0 days 00:01:51.518000  \n",
       "77  0 days 00:01:52.141000  \n",
       "78  0 days 00:01:48.218000  \n",
       "79  0 days 00:01:47.314000  \n",
       "80  0 days 00:01:46.846000  \n",
       "81  0 days 00:01:48.101000  \n",
       "82  0 days 00:01:48.306000  \n",
       "83  0 days 00:01:50.985000  \n",
       "84  0 days 00:01:47.649000  \n",
       "85  0 days 00:01:47.415000  \n",
       "86  0 days 00:01:47.598000  \n",
       "87  0 days 00:01:47.549000  \n",
       "88  0 days 00:01:47.522000  \n",
       "89  0 days 00:01:47.827000  \n",
       "90  0 days 00:01:47.433000  \n",
       "91  0 days 00:01:47.876000  \n",
       "92  0 days 00:01:47.705000  \n",
       "93  0 days 00:01:47.719000  \n",
       "94  0 days 00:01:49.050000  \n",
       "95  0 days 00:01:48.678000  \n",
       "96  0 days 00:02:11.374000  \n",
       "97                     NaT  \n",
       "98  0 days 00:02:24.593000  \n",
       "99                     NaT  \n",
       "100                    NaT  \n",
       "101 0 days 00:01:51.346000  \n",
       "102 0 days 00:01:49.119000  \n",
       "103                    NaT  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns\n",
    "test[['Time','LapStartTime','LapStartDate','LapTime']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
